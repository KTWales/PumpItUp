{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# plotting\n",
    "#import matplotlib.pyplot as plt\n",
    "#import seaborn as sns\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Building\n",
    "\n",
    "### Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>amount_tsh</th>\n",
       "      <th>gps_height</th>\n",
       "      <th>num_private</th>\n",
       "      <th>basin</th>\n",
       "      <th>region</th>\n",
       "      <th>district_code_recoded</th>\n",
       "      <th>population</th>\n",
       "      <th>public_meeting</th>\n",
       "      <th>recorded_by</th>\n",
       "      <th>scheme_management_recoded</th>\n",
       "      <th>...</th>\n",
       "      <th>management_group_recoded</th>\n",
       "      <th>payment_recoded</th>\n",
       "      <th>water_quality_recoded</th>\n",
       "      <th>source_recoded</th>\n",
       "      <th>source_type_recoded</th>\n",
       "      <th>source_class_recoded</th>\n",
       "      <th>waterpoint_type_recoded</th>\n",
       "      <th>waterpoint_type_group_recoded</th>\n",
       "      <th>quantity_recoded</th>\n",
       "      <th>status_group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6000.0</td>\n",
       "      <td>1390</td>\n",
       "      <td>0</td>\n",
       "      <td>Lake Nyasa</td>\n",
       "      <td>Iringa</td>\n",
       "      <td>Other Districts</td>\n",
       "      <td>109</td>\n",
       "      <td>True</td>\n",
       "      <td>GeoData Consultants Ltd</td>\n",
       "      <td>VWC</td>\n",
       "      <td>...</td>\n",
       "      <td>user-group</td>\n",
       "      <td>other</td>\n",
       "      <td>soft</td>\n",
       "      <td>spring</td>\n",
       "      <td>spring</td>\n",
       "      <td>groundwater</td>\n",
       "      <td>communal standpipe</td>\n",
       "      <td>communal standpipe</td>\n",
       "      <td>enough</td>\n",
       "      <td>functional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1399</td>\n",
       "      <td>0</td>\n",
       "      <td>Lake Victoria</td>\n",
       "      <td>Mara</td>\n",
       "      <td>District Codes 1-4</td>\n",
       "      <td>280</td>\n",
       "      <td>True</td>\n",
       "      <td>GeoData Consultants Ltd</td>\n",
       "      <td>Other</td>\n",
       "      <td>...</td>\n",
       "      <td>user-group</td>\n",
       "      <td>never pay</td>\n",
       "      <td>soft</td>\n",
       "      <td>other</td>\n",
       "      <td>other</td>\n",
       "      <td>surface</td>\n",
       "      <td>communal standpipe</td>\n",
       "      <td>communal standpipe</td>\n",
       "      <td>insufficient</td>\n",
       "      <td>functional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25.0</td>\n",
       "      <td>686</td>\n",
       "      <td>0</td>\n",
       "      <td>Pangani</td>\n",
       "      <td>Manyara</td>\n",
       "      <td>District Codes 1-4</td>\n",
       "      <td>250</td>\n",
       "      <td>True</td>\n",
       "      <td>GeoData Consultants Ltd</td>\n",
       "      <td>VWC</td>\n",
       "      <td>...</td>\n",
       "      <td>user-group</td>\n",
       "      <td>other</td>\n",
       "      <td>soft</td>\n",
       "      <td>other</td>\n",
       "      <td>other</td>\n",
       "      <td>surface</td>\n",
       "      <td>other</td>\n",
       "      <td>communal standpipe</td>\n",
       "      <td>enough</td>\n",
       "      <td>functional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>263</td>\n",
       "      <td>0</td>\n",
       "      <td>Ruvuma / Southern Coast</td>\n",
       "      <td>Mtwara</td>\n",
       "      <td>Other Districts</td>\n",
       "      <td>58</td>\n",
       "      <td>True</td>\n",
       "      <td>GeoData Consultants Ltd</td>\n",
       "      <td>VWC</td>\n",
       "      <td>...</td>\n",
       "      <td>user-group</td>\n",
       "      <td>never pay</td>\n",
       "      <td>soft</td>\n",
       "      <td>other</td>\n",
       "      <td>borehole</td>\n",
       "      <td>groundwater</td>\n",
       "      <td>other</td>\n",
       "      <td>communal standpipe</td>\n",
       "      <td>other</td>\n",
       "      <td>non functional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Lake Victoria</td>\n",
       "      <td>Kagera</td>\n",
       "      <td>District Codes 1-4</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>GeoData Consultants Ltd</td>\n",
       "      <td>Other</td>\n",
       "      <td>...</td>\n",
       "      <td>other</td>\n",
       "      <td>never pay</td>\n",
       "      <td>soft</td>\n",
       "      <td>other</td>\n",
       "      <td>other</td>\n",
       "      <td>surface</td>\n",
       "      <td>communal standpipe</td>\n",
       "      <td>communal standpipe</td>\n",
       "      <td>other</td>\n",
       "      <td>functional</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   amount_tsh  gps_height  num_private                    basin   region  \\\n",
       "0      6000.0        1390            0               Lake Nyasa   Iringa   \n",
       "1         0.0        1399            0            Lake Victoria     Mara   \n",
       "2        25.0         686            0                  Pangani  Manyara   \n",
       "3         0.0         263            0  Ruvuma / Southern Coast   Mtwara   \n",
       "4         0.0           0            0            Lake Victoria   Kagera   \n",
       "\n",
       "  district_code_recoded  population  public_meeting              recorded_by  \\\n",
       "0       Other Districts         109            True  GeoData Consultants Ltd   \n",
       "1    District Codes 1-4         280            True  GeoData Consultants Ltd   \n",
       "2    District Codes 1-4         250            True  GeoData Consultants Ltd   \n",
       "3       Other Districts          58            True  GeoData Consultants Ltd   \n",
       "4    District Codes 1-4           0            True  GeoData Consultants Ltd   \n",
       "\n",
       "  scheme_management_recoded  ...  management_group_recoded  payment_recoded  \\\n",
       "0                       VWC  ...                user-group            other   \n",
       "1                     Other  ...                user-group        never pay   \n",
       "2                       VWC  ...                user-group            other   \n",
       "3                       VWC  ...                user-group        never pay   \n",
       "4                     Other  ...                     other        never pay   \n",
       "\n",
       "  water_quality_recoded source_recoded source_type_recoded  \\\n",
       "0                  soft         spring              spring   \n",
       "1                  soft          other               other   \n",
       "2                  soft          other               other   \n",
       "3                  soft          other            borehole   \n",
       "4                  soft          other               other   \n",
       "\n",
       "  source_class_recoded waterpoint_type_recoded waterpoint_type_group_recoded  \\\n",
       "0          groundwater      communal standpipe            communal standpipe   \n",
       "1              surface      communal standpipe            communal standpipe   \n",
       "2              surface                   other            communal standpipe   \n",
       "3          groundwater                   other            communal standpipe   \n",
       "4              surface      communal standpipe            communal standpipe   \n",
       "\n",
       "  quantity_recoded    status_group  \n",
       "0           enough      functional  \n",
       "1     insufficient      functional  \n",
       "2           enough      functional  \n",
       "3            other  non functional  \n",
       "4            other      functional  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load Data:\n",
    "train = pd.read_pickle(\"train_clean.pickle\")\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([], dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Any missing values?\n",
    "train.columns[train.isnull().any()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 59400 entries, 0 to 59399\n",
      "Data columns (total 26 columns):\n",
      " #   Column                         Non-Null Count  Dtype  \n",
      "---  ------                         --------------  -----  \n",
      " 0   amount_tsh                     59400 non-null  float64\n",
      " 1   gps_height                     59400 non-null  int64  \n",
      " 2   num_private                    59400 non-null  int64  \n",
      " 3   basin                          59400 non-null  object \n",
      " 4   region                         59400 non-null  object \n",
      " 5   district_code_recoded          59400 non-null  object \n",
      " 6   population                     59400 non-null  int64  \n",
      " 7   public_meeting                 59400 non-null  bool   \n",
      " 8   recorded_by                    59400 non-null  object \n",
      " 9   scheme_management_recoded      59400 non-null  object \n",
      " 10  permit                         59400 non-null  bool   \n",
      " 11  construction_year              59400 non-null  int64  \n",
      " 12  extraction_type_recoded        59400 non-null  object \n",
      " 13  extraction_type_group          59400 non-null  object \n",
      " 14  extraction_type_class          59400 non-null  object \n",
      " 15  management_recoded             59400 non-null  object \n",
      " 16  management_group_recoded       59400 non-null  object \n",
      " 17  payment_recoded                59400 non-null  object \n",
      " 18  water_quality_recoded          59400 non-null  object \n",
      " 19  source_recoded                 59400 non-null  object \n",
      " 20  source_type_recoded            59400 non-null  object \n",
      " 21  source_class_recoded           59400 non-null  object \n",
      " 22  waterpoint_type_recoded        59400 non-null  object \n",
      " 23  waterpoint_type_group_recoded  59400 non-null  object \n",
      " 24  quantity_recoded               59400 non-null  object \n",
      " 25  status_group                   59400 non-null  object \n",
      "dtypes: bool(2), float64(1), int64(4), object(19)\n",
      "memory usage: 11.4+ MB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_numerical - Rows & Columns:  (59400, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>amount_tsh</th>\n",
       "      <th>gps_height</th>\n",
       "      <th>num_private</th>\n",
       "      <th>population</th>\n",
       "      <th>construction_year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6000.0</td>\n",
       "      <td>1390</td>\n",
       "      <td>0</td>\n",
       "      <td>109</td>\n",
       "      <td>1999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   amount_tsh  gps_height  num_private  population  construction_year\n",
       "0      6000.0        1390            0         109               1999"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Change object data type into character data type\n",
    "X_numerical = train.select_dtypes(exclude=['object','bool'])\n",
    "\n",
    "print(\"X_numerical - Rows & Columns: \", X_numerical.shape)\n",
    "X_numerical.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_categorical - Rows & Columns:  (59400, 20)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>basin</th>\n",
       "      <th>region</th>\n",
       "      <th>district_code_recoded</th>\n",
       "      <th>public_meeting</th>\n",
       "      <th>recorded_by</th>\n",
       "      <th>scheme_management_recoded</th>\n",
       "      <th>permit</th>\n",
       "      <th>extraction_type_recoded</th>\n",
       "      <th>extraction_type_group</th>\n",
       "      <th>extraction_type_class</th>\n",
       "      <th>management_recoded</th>\n",
       "      <th>management_group_recoded</th>\n",
       "      <th>payment_recoded</th>\n",
       "      <th>water_quality_recoded</th>\n",
       "      <th>source_recoded</th>\n",
       "      <th>source_type_recoded</th>\n",
       "      <th>source_class_recoded</th>\n",
       "      <th>waterpoint_type_recoded</th>\n",
       "      <th>waterpoint_type_group_recoded</th>\n",
       "      <th>quantity_recoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Lake Nyasa</td>\n",
       "      <td>Iringa</td>\n",
       "      <td>Other Districts</td>\n",
       "      <td>True</td>\n",
       "      <td>GeoData Consultants Ltd</td>\n",
       "      <td>VWC</td>\n",
       "      <td>False</td>\n",
       "      <td>gravity</td>\n",
       "      <td>gravity</td>\n",
       "      <td>gravity</td>\n",
       "      <td>vwc</td>\n",
       "      <td>user-group</td>\n",
       "      <td>other</td>\n",
       "      <td>soft</td>\n",
       "      <td>spring</td>\n",
       "      <td>spring</td>\n",
       "      <td>groundwater</td>\n",
       "      <td>communal standpipe</td>\n",
       "      <td>communal standpipe</td>\n",
       "      <td>enough</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        basin  region district_code_recoded  public_meeting  \\\n",
       "0  Lake Nyasa  Iringa       Other Districts            True   \n",
       "\n",
       "               recorded_by scheme_management_recoded  permit  \\\n",
       "0  GeoData Consultants Ltd                       VWC   False   \n",
       "\n",
       "  extraction_type_recoded extraction_type_group extraction_type_class  \\\n",
       "0                 gravity               gravity               gravity   \n",
       "\n",
       "  management_recoded management_group_recoded payment_recoded  \\\n",
       "0                vwc               user-group           other   \n",
       "\n",
       "  water_quality_recoded source_recoded source_type_recoded  \\\n",
       "0                  soft         spring              spring   \n",
       "\n",
       "  source_class_recoded waterpoint_type_recoded waterpoint_type_group_recoded  \\\n",
       "0          groundwater      communal standpipe            communal standpipe   \n",
       "\n",
       "  quantity_recoded  \n",
       "0           enough  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Change object data type into character data type\n",
    "X_categorical = train.select_dtypes(include=['object','bool'])\n",
    "X_categorical = X_categorical.drop('status_group', axis=1)\n",
    "\n",
    "print(\"X_categorical - Rows & Columns: \", X_categorical.shape)\n",
    "X_categorical.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y_categorical - Rows & Columns:  (59400,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0        functional\n",
       "1        functional\n",
       "2        functional\n",
       "3    non functional\n",
       "4        functional\n",
       "Name: status_group, dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Change object data type into character data type\n",
    "Y_categorical = train['status_group']\n",
    "\n",
    "print(\"Y_categorical - Rows & Columns: \", Y_categorical.shape)\n",
    "Y_categorical.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option 1: Using Get Dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>public_meeting</th>\n",
       "      <th>permit</th>\n",
       "      <th>dmy_Lake Nyasa</th>\n",
       "      <th>dmy_Lake Rukwa</th>\n",
       "      <th>dmy_Lake Tanganyika</th>\n",
       "      <th>dmy_Lake Victoria</th>\n",
       "      <th>dmy_Pangani</th>\n",
       "      <th>dmy_Rufiji</th>\n",
       "      <th>dmy_Ruvuma / Southern Coast</th>\n",
       "      <th>dmy_Wami / Ruvu</th>\n",
       "      <th>...</th>\n",
       "      <th>dmy_shallow well</th>\n",
       "      <th>dmy_spring</th>\n",
       "      <th>dmy_other</th>\n",
       "      <th>dmy_surface</th>\n",
       "      <th>dmy_hand pump</th>\n",
       "      <th>dmy_other</th>\n",
       "      <th>dmy_hand pump</th>\n",
       "      <th>dmy_other</th>\n",
       "      <th>dmy_insufficient</th>\n",
       "      <th>dmy_other</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 69 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   public_meeting  permit  dmy_Lake Nyasa  dmy_Lake Rukwa  \\\n",
       "0            True   False               1               0   \n",
       "1            True    True               0               0   \n",
       "2            True    True               0               0   \n",
       "3            True    True               0               0   \n",
       "4            True    True               0               0   \n",
       "\n",
       "   dmy_Lake Tanganyika  dmy_Lake Victoria  dmy_Pangani  dmy_Rufiji  \\\n",
       "0                    0                  0            0           0   \n",
       "1                    0                  1            0           0   \n",
       "2                    0                  0            1           0   \n",
       "3                    0                  0            0           0   \n",
       "4                    0                  1            0           0   \n",
       "\n",
       "   dmy_Ruvuma / Southern Coast  dmy_Wami / Ruvu  ...  dmy_shallow well  \\\n",
       "0                            0                0  ...                 0   \n",
       "1                            0                0  ...                 0   \n",
       "2                            0                0  ...                 0   \n",
       "3                            1                0  ...                 0   \n",
       "4                            0                0  ...                 0   \n",
       "\n",
       "   dmy_spring  dmy_other  dmy_surface  dmy_hand pump  dmy_other  \\\n",
       "0           1          0            0              0          0   \n",
       "1           0          0            1              0          0   \n",
       "2           0          0            1              0          1   \n",
       "3           0          0            0              0          1   \n",
       "4           0          0            1              0          0   \n",
       "\n",
       "   dmy_hand pump  dmy_other  dmy_insufficient  dmy_other  \n",
       "0              0          0                 0          0  \n",
       "1              0          0                 1          0  \n",
       "2              0          0                 0          0  \n",
       "3              0          0                 0          1  \n",
       "4              0          0                 0          1  \n",
       "\n",
       "[5 rows x 69 columns]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#X_categorical.permit = (X_categorical.permit.astype(str)).str.get_dummies().replace({1:'true', 0:'false'})\n",
    "#X_categorical.public_meeting = (X_categorical.public_meeting.astype(str)).str.get_dummies().replace({1:'true', 0:'false'})\n",
    "\n",
    "X_categorical_tf = pd.get_dummies(X_categorical, sparse=True, drop_first = True, prefix=\"dmy\", prefix_sep=\"_\")\n",
    "X_categorical_tf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(59400, 69)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_categorical_tf.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some machine learning models have trouble when the variables are of different size (0-100, vs 0-1000000). To deal with that we can scale the data. Here we will use scikit learn's Standard Scaler which removes the mean and scales to unit variance. Here I will create a scaler using all the training numerical fields."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['amount_tsh', 'gps_height', 'num_private', 'population',\n",
       "       'construction_year'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_numerical.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StandardScaler(copy=True, with_mean=True, with_std=True)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler  = StandardScaler()\n",
    "scaler.fit(X_numerical)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will need this scaler for the test data, so let's save it using a package called `pickle`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "scalerfile = 'scaler.sav' #'scaler.csv'\n",
    "pickle.dump(scaler, open(scalerfile, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_numerical_tf = scaler.transform(X_numerical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(59400, 5)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_numerical_tf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.89566509,  1.04125207, -0.03874931, -0.15039928,  0.52666618],\n",
       "       [-0.10597003,  1.05423701, -0.03874931,  0.21228981,  1.49940173],\n",
       "       [-0.09762988,  0.02554104, -0.03874931,  0.14866014,  1.41097123],\n",
       "       ...,\n",
       "       [-0.10597003, -0.96420011, -0.03874931, -0.38158706, -0.62293038],\n",
       "       [-0.10597003, -0.96420011, -0.03874931, -0.38158706, -0.62293038],\n",
       "       [-0.10597003, -0.68863079, -0.03874931, -0.06343874,  0.7919577 ]])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_numerical_tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_numerical_tf = pd.DataFrame(X_numerical_tf, columns=X_numerical.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>amount_tsh</th>\n",
       "      <th>gps_height</th>\n",
       "      <th>num_private</th>\n",
       "      <th>population</th>\n",
       "      <th>construction_year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.895665</td>\n",
       "      <td>1.041252</td>\n",
       "      <td>-0.038749</td>\n",
       "      <td>-0.150399</td>\n",
       "      <td>0.526666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.105970</td>\n",
       "      <td>1.054237</td>\n",
       "      <td>-0.038749</td>\n",
       "      <td>0.212290</td>\n",
       "      <td>1.499402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.097630</td>\n",
       "      <td>0.025541</td>\n",
       "      <td>-0.038749</td>\n",
       "      <td>0.148660</td>\n",
       "      <td>1.410971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.105970</td>\n",
       "      <td>-0.584751</td>\n",
       "      <td>-0.038749</td>\n",
       "      <td>-0.258570</td>\n",
       "      <td>-0.622930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.105970</td>\n",
       "      <td>-0.964200</td>\n",
       "      <td>-0.038749</td>\n",
       "      <td>-0.381587</td>\n",
       "      <td>-0.622930</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   amount_tsh  gps_height  num_private  population  construction_year\n",
       "0    1.895665    1.041252    -0.038749   -0.150399           0.526666\n",
       "1   -0.105970    1.054237    -0.038749    0.212290           1.499402\n",
       "2   -0.097630    0.025541    -0.038749    0.148660           1.410971\n",
       "3   -0.105970   -0.584751    -0.038749   -0.258570          -0.622930\n",
       "4   -0.105970   -0.964200    -0.038749   -0.381587          -0.622930"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_numerical_tf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "#concat with original data\n",
    "df_X_transform = pd.concat([X_numerical_tf, X_categorical_tf], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(59400, 74)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_X_transform.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>amount_tsh</th>\n",
       "      <th>gps_height</th>\n",
       "      <th>num_private</th>\n",
       "      <th>population</th>\n",
       "      <th>construction_year</th>\n",
       "      <th>public_meeting</th>\n",
       "      <th>permit</th>\n",
       "      <th>dmy_Lake Nyasa</th>\n",
       "      <th>dmy_Lake Rukwa</th>\n",
       "      <th>dmy_Lake Tanganyika</th>\n",
       "      <th>...</th>\n",
       "      <th>dmy_shallow well</th>\n",
       "      <th>dmy_spring</th>\n",
       "      <th>dmy_other</th>\n",
       "      <th>dmy_surface</th>\n",
       "      <th>dmy_hand pump</th>\n",
       "      <th>dmy_other</th>\n",
       "      <th>dmy_hand pump</th>\n",
       "      <th>dmy_other</th>\n",
       "      <th>dmy_insufficient</th>\n",
       "      <th>dmy_other</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.895665</td>\n",
       "      <td>1.041252</td>\n",
       "      <td>-0.038749</td>\n",
       "      <td>-0.150399</td>\n",
       "      <td>0.526666</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.105970</td>\n",
       "      <td>1.054237</td>\n",
       "      <td>-0.038749</td>\n",
       "      <td>0.212290</td>\n",
       "      <td>1.499402</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.097630</td>\n",
       "      <td>0.025541</td>\n",
       "      <td>-0.038749</td>\n",
       "      <td>0.148660</td>\n",
       "      <td>1.410971</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.105970</td>\n",
       "      <td>-0.584751</td>\n",
       "      <td>-0.038749</td>\n",
       "      <td>-0.258570</td>\n",
       "      <td>-0.622930</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.105970</td>\n",
       "      <td>-0.964200</td>\n",
       "      <td>-0.038749</td>\n",
       "      <td>-0.381587</td>\n",
       "      <td>-0.622930</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 74 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   amount_tsh  gps_height  num_private  population  construction_year  \\\n",
       "0    1.895665    1.041252    -0.038749   -0.150399           0.526666   \n",
       "1   -0.105970    1.054237    -0.038749    0.212290           1.499402   \n",
       "2   -0.097630    0.025541    -0.038749    0.148660           1.410971   \n",
       "3   -0.105970   -0.584751    -0.038749   -0.258570          -0.622930   \n",
       "4   -0.105970   -0.964200    -0.038749   -0.381587          -0.622930   \n",
       "\n",
       "   public_meeting  permit  dmy_Lake Nyasa  dmy_Lake Rukwa  \\\n",
       "0            True   False               1               0   \n",
       "1            True    True               0               0   \n",
       "2            True    True               0               0   \n",
       "3            True    True               0               0   \n",
       "4            True    True               0               0   \n",
       "\n",
       "   dmy_Lake Tanganyika  ...  dmy_shallow well  dmy_spring  dmy_other  \\\n",
       "0                    0  ...                 0           1          0   \n",
       "1                    0  ...                 0           0          0   \n",
       "2                    0  ...                 0           0          0   \n",
       "3                    0  ...                 0           0          0   \n",
       "4                    0  ...                 0           0          0   \n",
       "\n",
       "   dmy_surface  dmy_hand pump  dmy_other  dmy_hand pump  dmy_other  \\\n",
       "0            0              0          0              0          0   \n",
       "1            1              0          0              0          0   \n",
       "2            1              0          1              0          0   \n",
       "3            0              0          1              0          0   \n",
       "4            1              0          0              0          0   \n",
       "\n",
       "   dmy_insufficient  dmy_other  \n",
       "0                 0          0  \n",
       "1                 1          0  \n",
       "2                 0          0  \n",
       "3                 0          1  \n",
       "4                 0          1  \n",
       "\n",
       "[5 rows x 74 columns]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_X_transform.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['amount_tsh',\n",
       " 'gps_height',\n",
       " 'num_private',\n",
       " 'population',\n",
       " 'construction_year',\n",
       " 'public_meeting',\n",
       " 'permit',\n",
       " 'dmy_Lake Nyasa',\n",
       " 'dmy_Lake Rukwa',\n",
       " 'dmy_Lake Tanganyika',\n",
       " 'dmy_Lake Victoria',\n",
       " 'dmy_Pangani',\n",
       " 'dmy_Rufiji',\n",
       " 'dmy_Ruvuma / Southern Coast',\n",
       " 'dmy_Wami / Ruvu',\n",
       " 'dmy_Dar es Salaam',\n",
       " 'dmy_Dodoma',\n",
       " 'dmy_Iringa',\n",
       " 'dmy_Kagera',\n",
       " 'dmy_Kigoma',\n",
       " 'dmy_Kilimanjaro',\n",
       " 'dmy_Lindi',\n",
       " 'dmy_Manyara',\n",
       " 'dmy_Mara',\n",
       " 'dmy_Mbeya',\n",
       " 'dmy_Morogoro',\n",
       " 'dmy_Mtwara',\n",
       " 'dmy_Mwanza',\n",
       " 'dmy_Pwani',\n",
       " 'dmy_Rukwa',\n",
       " 'dmy_Ruvuma',\n",
       " 'dmy_Shinyanga',\n",
       " 'dmy_Singida',\n",
       " 'dmy_Tabora',\n",
       " 'dmy_Tanga',\n",
       " 'dmy_Other Districts',\n",
       " 'dmy_VWC',\n",
       " 'dmy_other',\n",
       " 'dmy_gravity',\n",
       " 'dmy_india mark ii',\n",
       " 'dmy_india mark iii',\n",
       " 'dmy_mono',\n",
       " 'dmy_nira/tanira',\n",
       " 'dmy_other',\n",
       " 'dmy_other handpump',\n",
       " 'dmy_other motorpump',\n",
       " 'dmy_rope pump',\n",
       " 'dmy_submersible',\n",
       " 'dmy_swn 80',\n",
       " 'dmy_wind-powered',\n",
       " 'dmy_handpump',\n",
       " 'dmy_motorpump',\n",
       " 'dmy_other',\n",
       " 'dmy_rope pump',\n",
       " 'dmy_submersible',\n",
       " 'dmy_wind-powered',\n",
       " 'dmy_vwc',\n",
       " 'dmy_user-group',\n",
       " 'dmy_other',\n",
       " 'dmy_soft',\n",
       " 'dmy_shallow well',\n",
       " 'dmy_spring',\n",
       " 'dmy_other',\n",
       " 'dmy_river/lake',\n",
       " 'dmy_shallow well',\n",
       " 'dmy_spring',\n",
       " 'dmy_other',\n",
       " 'dmy_surface',\n",
       " 'dmy_hand pump',\n",
       " 'dmy_other',\n",
       " 'dmy_hand pump',\n",
       " 'dmy_other',\n",
       " 'dmy_insufficient',\n",
       " 'dmy_other']"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the column names\n",
    "df_X_transform_columns = list(df_X_transform.columns)\n",
    "df_X_transform_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input All Xs (59400, 74)\n",
      "\n",
      "Target Y (59400,)\n",
      "[0 0 0 ... 0 0 0]\n",
      "\n",
      "status_group_cat  status_group           \n",
      "0                 functional                 32259\n",
      "1                 functional needs repair     4317\n",
      "2                 non functional             22824\n",
      "Name: status_group, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# one hot encode target variable\n",
    "label_encoder = LabelEncoder()\n",
    "df_y_transform = label_encoder.fit_transform(Y_categorical)\n",
    "\n",
    "# summarize the transformed data\n",
    "print('Input All Xs', df_X_transform.shape)\n",
    "print('')\n",
    "\n",
    "print('Target Y', df_y_transform.shape)\n",
    "print(df_y_transform[:,])\n",
    "print('')\n",
    "\n",
    "df_Y_categorical['status_group_cat'] = labelencoder.fit_transform(df_Y_categorical['status_group'])\n",
    "print(df_Y_categorical.groupby(['status_group_cat','status_group'])['status_group'].count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option 2: Using One-Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Categorical Xs (59400, 89)\n",
      "[[0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 1. 0. 1. 1. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 1. 0. 1. 0. 0. 1.\n",
      "  0. 0. 0. 0. 1. 1. 0. 0. 1. 0. 0. 1. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1. 1. 0. 0. 1. 1. 0. 0. 1. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1. 0. 0. 1. 1. 0. 0.\n",
      "  0. 1. 0. 0. 0. 0. 0. 1. 1. 0. 0. 1. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1. 0. 1. 0. 1. 1. 0. 0. 1. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 1. 0. 1. 1. 0. 0.\n",
      "  0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 1. 0. 1. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 1. 1. 0. 0. 1. 1. 0. 0.\n",
      "  1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1. 1. 0. 0. 1. 1. 0. 0. 1. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 1. 0. 0. 1. 1. 0. 0.\n",
      "  0. 1. 0. 0. 0. 0. 0. 1. 1. 0. 0. 1. 0. 0. 0. 0. 1.]]\n",
      "Target Y (59400,)\n",
      "[0 0 0 ... 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# one hot encode input variables\n",
    "onehot_encoder = OneHotEncoder(sparse=False)\n",
    "df_X_transform2 = onehot_encoder.fit_transform(X_categorical)\n",
    "\n",
    "# one hot encode target variable\n",
    "label_encoder = LabelEncoder()\n",
    "df_y_transform2 = label_encoder.fit_transform(Y_categorical)\n",
    "\n",
    "# summarize the transformed data\n",
    "print('Input Categorical Xs', df_X_transform2.shape)\n",
    "print(df_X_transform2[:5, :])\n",
    "\n",
    "print('Target Y', df_y_transform2.shape)\n",
    "print(df_y_transform2[:,])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting the array into a pandas dataframe\n",
    "# Create a Pandas DataFrame of the hot encoded columns\n",
    "df_X_transform2_ = pd.DataFrame(df_X_transform2, columns=onehot_encoder.get_feature_names())\n",
    "\n",
    "#concat with original data\n",
    "df_X_transform_onehot = pd.concat([X_numerical_tf, df_X_transform2_], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(59400, 89)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_X_transform2_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input All Xs (59400, 94)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>amount_tsh</th>\n",
       "      <th>gps_height</th>\n",
       "      <th>num_private</th>\n",
       "      <th>population</th>\n",
       "      <th>construction_year</th>\n",
       "      <th>x0_Internal</th>\n",
       "      <th>x0_Lake Nyasa</th>\n",
       "      <th>x0_Lake Rukwa</th>\n",
       "      <th>x0_Lake Tanganyika</th>\n",
       "      <th>x0_Lake Victoria</th>\n",
       "      <th>...</th>\n",
       "      <th>x16_surface</th>\n",
       "      <th>x17_communal standpipe</th>\n",
       "      <th>x17_hand pump</th>\n",
       "      <th>x17_other</th>\n",
       "      <th>x18_communal standpipe</th>\n",
       "      <th>x18_hand pump</th>\n",
       "      <th>x18_other</th>\n",
       "      <th>x19_enough</th>\n",
       "      <th>x19_insufficient</th>\n",
       "      <th>x19_other</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.895665</td>\n",
       "      <td>1.041252</td>\n",
       "      <td>-0.038749</td>\n",
       "      <td>-0.150399</td>\n",
       "      <td>0.526666</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.105970</td>\n",
       "      <td>1.054237</td>\n",
       "      <td>-0.038749</td>\n",
       "      <td>0.212290</td>\n",
       "      <td>1.499402</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.097630</td>\n",
       "      <td>0.025541</td>\n",
       "      <td>-0.038749</td>\n",
       "      <td>0.148660</td>\n",
       "      <td>1.410971</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.105970</td>\n",
       "      <td>-0.584751</td>\n",
       "      <td>-0.038749</td>\n",
       "      <td>-0.258570</td>\n",
       "      <td>-0.622930</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.105970</td>\n",
       "      <td>-0.964200</td>\n",
       "      <td>-0.038749</td>\n",
       "      <td>-0.381587</td>\n",
       "      <td>-0.622930</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 94 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   amount_tsh  gps_height  num_private  population  construction_year  \\\n",
       "0    1.895665    1.041252    -0.038749   -0.150399           0.526666   \n",
       "1   -0.105970    1.054237    -0.038749    0.212290           1.499402   \n",
       "2   -0.097630    0.025541    -0.038749    0.148660           1.410971   \n",
       "3   -0.105970   -0.584751    -0.038749   -0.258570          -0.622930   \n",
       "4   -0.105970   -0.964200    -0.038749   -0.381587          -0.622930   \n",
       "\n",
       "   x0_Internal  x0_Lake Nyasa  x0_Lake Rukwa  x0_Lake Tanganyika  \\\n",
       "0          0.0            1.0            0.0                 0.0   \n",
       "1          0.0            0.0            0.0                 0.0   \n",
       "2          0.0            0.0            0.0                 0.0   \n",
       "3          0.0            0.0            0.0                 0.0   \n",
       "4          0.0            0.0            0.0                 0.0   \n",
       "\n",
       "   x0_Lake Victoria  ...  x16_surface  x17_communal standpipe  x17_hand pump  \\\n",
       "0               0.0  ...          0.0                     1.0            0.0   \n",
       "1               1.0  ...          1.0                     1.0            0.0   \n",
       "2               0.0  ...          1.0                     0.0            0.0   \n",
       "3               0.0  ...          0.0                     0.0            0.0   \n",
       "4               1.0  ...          1.0                     1.0            0.0   \n",
       "\n",
       "   x17_other  x18_communal standpipe  x18_hand pump  x18_other  x19_enough  \\\n",
       "0        0.0                     1.0            0.0        0.0         1.0   \n",
       "1        0.0                     1.0            0.0        0.0         0.0   \n",
       "2        1.0                     1.0            0.0        0.0         1.0   \n",
       "3        1.0                     1.0            0.0        0.0         0.0   \n",
       "4        0.0                     1.0            0.0        0.0         0.0   \n",
       "\n",
       "   x19_insufficient  x19_other  \n",
       "0               0.0        0.0  \n",
       "1               1.0        0.0  \n",
       "2               0.0        0.0  \n",
       "3               0.0        1.0  \n",
       "4               0.0        1.0  \n",
       "\n",
       "[5 rows x 94 columns]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Input All Xs', df_X_transform_onehot.shape)\n",
    "df_X_transform_onehot.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(59400, 94) (59400,)\n",
      "Counter({0: 32259, 2: 22824, 1: 4317})\n"
     ]
    }
   ],
   "source": [
    "# summarize the dataset\n",
    "from collections import Counter\n",
    "\n",
    "print(df_X_transform_onehot.shape, df_y_transform2.shape)\n",
    "print(Counter(df_y_transform2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['amount_tsh',\n",
       " 'gps_height',\n",
       " 'num_private',\n",
       " 'population',\n",
       " 'construction_year',\n",
       " 'x0_Internal',\n",
       " 'x0_Lake Nyasa',\n",
       " 'x0_Lake Rukwa',\n",
       " 'x0_Lake Tanganyika',\n",
       " 'x0_Lake Victoria',\n",
       " 'x0_Pangani',\n",
       " 'x0_Rufiji',\n",
       " 'x0_Ruvuma / Southern Coast',\n",
       " 'x0_Wami / Ruvu',\n",
       " 'x1_Arusha',\n",
       " 'x1_Dar es Salaam',\n",
       " 'x1_Dodoma',\n",
       " 'x1_Iringa',\n",
       " 'x1_Kagera',\n",
       " 'x1_Kigoma',\n",
       " 'x1_Kilimanjaro',\n",
       " 'x1_Lindi',\n",
       " 'x1_Manyara',\n",
       " 'x1_Mara',\n",
       " 'x1_Mbeya',\n",
       " 'x1_Morogoro',\n",
       " 'x1_Mtwara',\n",
       " 'x1_Mwanza',\n",
       " 'x1_Pwani',\n",
       " 'x1_Rukwa',\n",
       " 'x1_Ruvuma',\n",
       " 'x1_Shinyanga',\n",
       " 'x1_Singida',\n",
       " 'x1_Tabora',\n",
       " 'x1_Tanga',\n",
       " 'x2_District Codes 1-4',\n",
       " 'x2_Other Districts',\n",
       " 'x3_False',\n",
       " 'x3_True',\n",
       " 'x4_GeoData Consultants Ltd',\n",
       " 'x5_Other',\n",
       " 'x5_VWC',\n",
       " 'x6_False',\n",
       " 'x6_True',\n",
       " 'x7_gravity',\n",
       " 'x7_other',\n",
       " 'x8_afridev',\n",
       " 'x8_gravity',\n",
       " 'x8_india mark ii',\n",
       " 'x8_india mark iii',\n",
       " 'x8_mono',\n",
       " 'x8_nira/tanira',\n",
       " 'x8_other',\n",
       " 'x8_other handpump',\n",
       " 'x8_other motorpump',\n",
       " 'x8_rope pump',\n",
       " 'x8_submersible',\n",
       " 'x8_swn 80',\n",
       " 'x8_wind-powered',\n",
       " 'x9_gravity',\n",
       " 'x9_handpump',\n",
       " 'x9_motorpump',\n",
       " 'x9_other',\n",
       " 'x9_rope pump',\n",
       " 'x9_submersible',\n",
       " 'x9_wind-powered',\n",
       " 'x10_other',\n",
       " 'x10_vwc',\n",
       " 'x11_other',\n",
       " 'x11_user-group',\n",
       " 'x12_never pay',\n",
       " 'x12_other',\n",
       " 'x13_other',\n",
       " 'x13_soft',\n",
       " 'x14_other',\n",
       " 'x14_shallow well',\n",
       " 'x14_spring',\n",
       " 'x15_borehole',\n",
       " 'x15_other',\n",
       " 'x15_river/lake',\n",
       " 'x15_shallow well',\n",
       " 'x15_spring',\n",
       " 'x16_groundwater',\n",
       " 'x16_other',\n",
       " 'x16_surface',\n",
       " 'x17_communal standpipe',\n",
       " 'x17_hand pump',\n",
       " 'x17_other',\n",
       " 'x18_communal standpipe',\n",
       " 'x18_hand pump',\n",
       " 'x18_other',\n",
       " 'x19_enough',\n",
       " 'x19_insufficient',\n",
       " 'x19_other']"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the column names\n",
    "df_X_transform_columns = list(df_X_transform_onehot.columns)\n",
    "df_X_transform_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "status_group_cat  status_group           \n",
      "0                 functional                 32259\n",
      "1                 functional needs repair     4317\n",
      "2                 non functional             22824\n",
      "Name: status_group, dtype: int64\n",
      "\n",
      "Input X:  (59400, 94)\n",
      "Target Y:  (59400,)\n"
     ]
    }
   ],
   "source": [
    "# Assigning numerical values and storing in another column\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# creating initial dataframe \n",
    "df_Y_categorical = pd.DataFrame(Y_categorical, columns=['status_group'])\n",
    "\n",
    "# creating instance of labelencoder\n",
    "labelencoder = LabelEncoder()\n",
    "\n",
    "df_Y_categorical['status_group_cat'] = labelencoder.fit_transform(df_Y_categorical['status_group'])\n",
    "print(df_Y_categorical.groupby(['status_group_cat','status_group'])['status_group'].count())\n",
    "print('')\n",
    "\n",
    "# summarize the dataset\n",
    "#from collections import Counter\n",
    "\n",
    "print('Input X: ',df_X_transform_onehot.shape)\n",
    "print('Target Y: ', df_y_transform2.shape)\n",
    "#print(Counter(df_y_transform))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multinomial Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate multinomial logistic regression model\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# define dataset\n",
    "#X, y = make_classification(n_samples=1000, n_features=10, n_informative=5, n_redundant=5, n_classes=3, random_state=1)\n",
    "\n",
    "# define the multinomial logistic regression model\n",
    "model = LogisticRegression(multi_class='multinomial', solver='lbfgs')\n",
    "\n",
    "# we will evaluate the model using repeated k-fold cross-validation, with three repeats and 10 folds.\n",
    "# define the model evaluation procedure\n",
    "cv = RepeatedStratifiedKFold(n_splits=2, n_repeats=1, random_state=1)\n",
    "\n",
    "# evaluate the model and collect the scores\n",
    "n_scores = cross_val_score(model, df_X_transform, df_y_transform, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "\n",
    "# report the model performance\n",
    "print('Mean Accuracy: %.3f (%.3f)' % (mean(n_scores), std(n_scores)))\n",
    "\n",
    "# fit the model on the whole dataset\n",
    "model.fit(df_X_transform, df_y_transform)\n",
    "\n",
    "# define a single row of input data\n",
    "# need to recode some variables\n",
    "row = df_X_transform.head(1)\n",
    "#row = df_test_clean_transform.head(1)\n",
    "\n",
    "# predict the class label\n",
    "yhat = model.predict(row)\n",
    "\n",
    "# summarize the predicted class\n",
    "print('Actual Class: %d' % df_y_transform[0])\n",
    "print('Predicted Class: %d' % yhat[0])\n",
    "\n",
    "# predict a multinomial probability distribution\n",
    "yhat = model.predict_proba(row)\n",
    "\n",
    "# summarize the predicted probabilities\n",
    "print('Predicted Probabilities: %s' % yhat[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Singleton array 0 cannot be considered a valid collection.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-105-8bffadb3d245>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'F1 score: '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf1_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_y_transform\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myhat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Accuracy: '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_y_transform\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myhat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mf1_score\u001b[0;34m(y_true, y_pred, labels, pos_label, average, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m   1097\u001b[0m                        \u001b[0mpos_label\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpos_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maverage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1098\u001b[0m                        \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1099\u001b[0;31m                        zero_division=zero_division)\n\u001b[0m\u001b[1;32m   1100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mfbeta_score\u001b[0;34m(y_true, y_pred, beta, labels, pos_label, average, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m   1224\u001b[0m                                                  \u001b[0mwarn_for\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'f-score'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1225\u001b[0m                                                  \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1226\u001b[0;31m                                                  zero_division=zero_division)\n\u001b[0m\u001b[1;32m   1227\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1228\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mprecision_recall_fscore_support\u001b[0;34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m   1482\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"beta should be >=0 in the F-beta score\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1483\u001b[0m     labels = _check_set_wise_labels(y_true, y_pred, average, labels,\n\u001b[0;32m-> 1484\u001b[0;31m                                     pos_label)\n\u001b[0m\u001b[1;32m   1485\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1486\u001b[0m     \u001b[0;31m# Calculate tp_sum, pred_sum, true_sum ###\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_set_wise_labels\u001b[0;34m(y_true, y_pred, average, labels, pos_label)\u001b[0m\n\u001b[1;32m   1299\u001b[0m                          str(average_options))\n\u001b[1;32m   1300\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1301\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1302\u001b[0m     \u001b[0mpresent_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munique_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1303\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0maverage\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'binary'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0marray\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mindicator\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m     \"\"\"\n\u001b[0;32m---> 80\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m     \u001b[0mtype_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m     \u001b[0mtype_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \"\"\"\n\u001b[1;32m    207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m     \u001b[0mlengths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_num_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mX\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mX\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m     \u001b[0muniques\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \"\"\"\n\u001b[1;32m    207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m     \u001b[0mlengths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_num_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mX\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mX\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m     \u001b[0muniques\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_num_samples\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    150\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m             raise TypeError(\"Singleton array %r cannot be considered\"\n\u001b[0;32m--> 152\u001b[0;31m                             \" a valid collection.\" % x)\n\u001b[0m\u001b[1;32m    153\u001b[0m         \u001b[0;31m# Check that shape is returning an integer or default to len\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m         \u001b[0;31m# Dask dataframes may not return numeric shape[0] value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Singleton array 0 cannot be considered a valid collection."
     ]
    }
   ],
   "source": [
    "# Checking Model Validation\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print('F1 score: ', f1_score(df_y_transform[0], yhat[0]))\n",
    "print('Accuracy: ', accuracy_score(df_y_transform[0], yhat[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest for Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.775 (0.001)\n",
      "Actual Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Probabilities: [0.98 0.02 0.  ]\n"
     ]
    }
   ],
   "source": [
    "# evaluate random forest ensemble for regression\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# define dataset\n",
    "#X, y = make_regression(n_samples=1000, n_features=20, n_informative=15, noise=0.1, random_state=2)\n",
    "\n",
    "# define the model\n",
    "model = RandomForestClassifier()\n",
    "\n",
    "# evaluate the model\n",
    "#We will evaluate the model using repeated k-fold cross-validation, with three repeats and 10 folds.\n",
    "cv = RepeatedKFold(n_splits=2, n_repeats=1, random_state=1)\n",
    "\n",
    "# evaluate the model and collect the scores\n",
    "n_scores = cross_val_score(model, df_X_transform, df_y_transform, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "\n",
    "# report the model performance\n",
    "print('Accuracy: %.3f (%.3f)' % (mean(n_scores), std(n_scores)))\n",
    "\n",
    "# fit the model on the whole dataset\n",
    "model.fit(df_X_transform, df_y_transform)\n",
    "\n",
    "# define a single row of input data\n",
    "# need to recode some variables\n",
    "row = df_X_transform.head(1)\n",
    "#row = df_test_clean_transform.head(1)\n",
    "\n",
    "# predict the class label\n",
    "yhat = model.predict(row)\n",
    "\n",
    "# summarize the predicted class\n",
    "print('Actual Class: %d' % df_y_transform[0])\n",
    "print('Predicted Class: %d' % yhat[0])\n",
    "\n",
    "# predict a multinomial probability distribution\n",
    "yhat = model.predict_proba(row)\n",
    "\n",
    "# summarize the predicted probabilities\n",
    "print('Predicted Probabilities: %s' % yhat[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.733 (0.002)\n",
      "Actual Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Probabilities: [1. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "# evaluate multioutput regression model with k-fold cross-validation\n",
    "from numpy import absolute\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "\n",
    "# create datasets\n",
    "#X, y = make_regression(n_samples=1000, n_features=10, n_informative=5, n_targets=2, random_state=1, noise=0.5)\n",
    "\n",
    "# define model\n",
    "model = DecisionTreeClassifier()\n",
    "\n",
    "# define the evaluation procedure\n",
    "#We will evaluate the model using repeated k-fold cross-validation, with three repeats and 10 folds.\n",
    "cv = RepeatedKFold(n_splits=2, n_repeats=1, random_state=1)\n",
    "\n",
    "# evaluate the model and collect the scores\n",
    "n_scores = cross_val_score(model, df_X_transform, df_y_transform, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "\n",
    "# force the scores to be positive\n",
    "n_scores = absolute(n_scores)\n",
    "\n",
    "# summarize performance\n",
    "print('Accuracy: %.3f (%.3f)' % (mean(n_scores), std(n_scores)))\n",
    "\n",
    "# define model\n",
    "model = DecisionTreeClassifier()\n",
    "\n",
    "# fit the model on the whole dataset\n",
    "model.fit(df_X_transform, df_y_transform)\n",
    "\n",
    "# define a single row of input data\n",
    "# need to recode some variables\n",
    "row = df_X_transform.head(1)\n",
    "#row = df_test_clean_transform.head(1)\n",
    "\n",
    "# predict the class label\n",
    "yhat = model.predict(row)\n",
    "\n",
    "# summarize the predicted class\n",
    "print('Actual Class: %d' % df_y_transform[0])\n",
    "print('Predicted Class: %d' % yhat[0])\n",
    "\n",
    "# predict a multinomial probability distribution\n",
    "yhat = model.predict_proba(row)\n",
    "\n",
    "# summarize the predicted probabilities\n",
    "print('Predicted Probabilities: %s' % yhat[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References:\n",
    "\n",
    "1. Get Dummies: https://www.dataindependent.com/pandas/pandas-get-dummies/\n",
    "2. One-Hot Encoding: https://machinelearningmastery.com/one-hot-encoding-for-categorical-data/\n",
    "3. One-Hot Encoding on Categorical Data: https://towardsdatascience.com/categorical-encoding-using-label-encoding-and-one-hot-encoder-911ef77fb5bd\n",
    "4. Multinomial Logistic Regression: https://machinelearningmastery.com/multinomial-logistic-regression-with-python/\n",
    "5. Random Forest: https://machinelearningmastery.com/random-forest-ensemble-in-python/\n",
    "6. Decision Tree: https://machinelearningmastery.com/multi-output-regression-models-with-python/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
